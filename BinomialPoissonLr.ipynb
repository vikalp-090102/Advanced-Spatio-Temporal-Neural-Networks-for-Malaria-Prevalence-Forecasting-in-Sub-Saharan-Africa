{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEEYmFstMK-d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from datetime import datetime\n",
        "\n",
        "# --- 1. Data Loading and Initial Preparation ---\n",
        "def load_and_prepare_data(file_path='/content/AfricaDataset.csv.csv'):\n",
        "\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Loads the dataset, cleans it, and prepares it for analysis and modeling.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file {file_path} was not found. Please ensure it's in the same directory.\")\n",
        "        return None\n",
        "\n",
        "    # Drop fully null columns\n",
        "    df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17'], errors='ignore')\n",
        "\n",
        "    # Convert MM and YY to a proper datetime object for time-series analysis\n",
        "    # Some dates might be problematic (e.g., MM=0, YY too low/high), handle errors\n",
        "    df['Date'] = pd.to_datetime(df['YY'].astype(str) + '-' + df['MM'].astype(str) + '-01', errors='coerce')\n",
        "\n",
        "    # Drop rows where Date could not be parsed\n",
        "    df.dropna(subset=['Date'], inplace=True)\n",
        "\n",
        "    # Feature Engineering for Prediction\n",
        "    df['Year'] = df['Date'].dt.year\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "    df['DayOfYear'] = df['Date'].dt.dayofyear # Useful for seasonality\n",
        "\n",
        "    print(\"Data loaded and prepared. First 5 rows:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nData Info:\")\n",
        "    print(df.info())\n",
        "    return df\n",
        "\n",
        "# --- 2. Predictive Model for Malaria Prevalence (PfPR2-10) ---\n",
        "def train_and_predict_malaria(df):\n",
        "    \"\"\"\n",
        "    Trains a simple RandomForestRegressor model to predict PfPR2-10.\n",
        "    This example uses geographical and temporal features.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Training Predictive Model ---\")\n",
        "\n",
        "    # Select features for prediction\n",
        "    # We use Lat, Long, Year, Month, DayOfYear as features\n",
        "    features = ['Lat', 'Long', 'Year', 'Month', 'DayOfYear']\n",
        "    target = 'PfPR2-10'\n",
        "\n",
        "    # Filter out rows with NaN in features or target\n",
        "    df_model = df.dropna(subset=features + [target])\n",
        "\n",
        "    if df_model.empty:\n",
        "        print(\"Not enough data to train the model after dropping NaNs.\")\n",
        "        return None, None\n",
        "\n",
        "    X = df_model[features]\n",
        "    y = df_model[target]\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Initialize and train the model\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Model Training Complete.\")\n",
        "    print(f\"Mean Absolute Error on Test Set: {mae:.2f}\")\n",
        "    print(f\"R-squared Score on Test Set: {r2:.2f}\")\n",
        "\n",
        "    # Example of making a future prediction\n",
        "    # Let's predict for a hypothetical point in Angola in July 2025\n",
        "    # (assuming similar Lat/Long as an existing Angola point)\n",
        "    # This is a simplification; for real future prediction, you'd need\n",
        "    # to consider specific locations and their time series.\n",
        "    example_lat = -8.0\n",
        "    example_long = 13.0\n",
        "    future_year = 2025\n",
        "    future_month = 7\n",
        "    future_date = pd.Timestamp(future_year, future_month, 15) # Use 15th for DayOfYear calculation\n",
        "    future_dayofyear = future_date.dayofyear\n",
        "\n",
        "    future_data = pd.DataFrame([[example_lat, example_long, future_year, future_month, future_dayofyear]],\n",
        "                               columns=features)\n",
        "    future_prediction = model.predict(future_data)[0]\n",
        "    print(f\"\\nExample Future Prediction (Hypothetical Point at Lat {example_lat}, Long {example_long}, July {future_year}):\")\n",
        "    print(f\"Predicted PfPR2-10: {future_prediction:.2f}%\")\n",
        "\n",
        "    return model, features\n",
        "\n",
        "# --- 3. Basic Question Answering from Dataset ---\n",
        "def answer_basic_questions(df):\n",
        "    \"\"\"\n",
        "    Provides examples of how to answer common questions directly from the DataFrame.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Answering Basic Questions from Dataset ---\")\n",
        "\n",
        "    # Q1: What is the average PfPR2-10 in a specific country (e.g., Angola)?\n",
        "    country_name = 'Angola'\n",
        "    angola_data = df[df['COUNTRY'] == country_name]\n",
        "    if not angola_data.empty:\n",
        "        avg_pfpr = angola_data['PfPR2-10'].mean()\n",
        "        print(f\"1. Average PfPR2-10 in {country_name}: {avg_pfpr:.2f}%\")\n",
        "    else:\n",
        "        print(f\"1. No data found for {country_name}.\")\n",
        "\n",
        "    # Q2: Which diagnostic methods are present in the dataset and their counts?\n",
        "    method_counts = df['METHOD'].value_counts()\n",
        "    print(\"\\n2. Diagnostic Methods and their Counts:\")\n",
        "    print(method_counts)\n",
        "\n",
        "    # Q3: What is the highest PfPR2-10 recorded and where/when?\n",
        "    max_pfpr_row = df.loc[df['PfPR2-10'].idxmax()]\n",
        "    print(f\"\\n3. Highest PfPR2-10 Recorded:\")\n",
        "    print(f\"   Value: {max_pfpr_row['PfPR2-10']:.2f}%\")\n",
        "    print(f\"   Country: {max_pfpr_row['COUNTRY']}\")\n",
        "    print(f\"   Location: {max_pfpr_row['AFR Admin name']} (Lat: {max_pfpr_row['Lat']:.2f}, Long: {max_pfpr_row['Long']:.2f})\")\n",
        "    print(f\"   Date: {max_pfpr_row['Date'].strftime('%Y-%m')}\")\n",
        "\n",
        "    # Q4: How has the average PfPR2-10 changed over time (yearly)?\n",
        "    yearly_avg_pfpr = df.groupby('Year')['PfPR2-10'].mean().sort_index()\n",
        "    print(\"\\n4. Average PfPR2-10 over the years:\")\n",
        "    print(yearly_avg_pfpr.to_string())\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    df = load_and_prepare_data()\n",
        "\n",
        "    if df is not None:\n",
        "        model, features = train_and_predict_malaria(df)\n",
        "        answer_basic_questions(df)\n",
        "\n",
        "        print(\"\\n--- Next Steps for Building the LLM RAG Chatbot in PyCharm ---\")\n",
        "        print(\"To create a full LLM RAG chatbot, you will combine the above functionalities with an LLM.\")\n",
        "        print(\"\\n**Conceptual Architecture:**\")\n",
        "        print(\"1.  **User Query:** The user asks a question (e.g., 'What's the predicted malaria prevalence in Angola next year?' or 'What are the diagnostic methods?').\")\n",
        "        print(\"2.  **Intent Recognition (Optional but Recommended):** An initial classifier or a small LLM can determine if the query is for prediction or factual Q&A.\")\n",
        "        print(\"3.  **Retrieval System (RAG Component):**\")\n",
        "        print(\"    * **For Factual Q&A:** If it's a factual question, the system queries the pandas DataFrame (as shown in `answer_basic_questions`) or a more sophisticated knowledge base (e.g., a vector store of external malaria facts).\")\n",
        "        print(\"    * **For Prediction:** If it's a prediction query, extract parameters (e.g., location, date) and feed them to the trained `model` (from `train_and_predict_malaria`).\")\n",
        "        print(\"4.  **Context Construction:** The retrieved data (e.g., DataFrame query results, prediction output, or retrieved facts from a vector store) is formatted into a context string.\")\n",
        "        print(\"5.  **LLM Prompt Engineering:** A prompt is crafted for the LLM, incorporating the user's original query and the retrieved context.\")\n",
        "        print(\"    Example Prompt: 'Based on the following data: [RETRIEVED_CONTEXT], answer the question: [USER_QUERY]'\")\n",
        "        print(\"6.  **LLM Generation:** The LLM generates a natural language answer based on the prompt.\")\n",
        "        print(\"7.  **Chatbot Interface:** Present the LLM's answer to the user.\")\n",
        "\n",
        "        print(\"\\n**Key Libraries for PyCharm Implementation:**\")\n",
        "        print(\"   * **Data Handling:** `pandas`, `numpy` (already used)\")\n",
        "        print(\"   * **Machine Learning:** `scikit-learn` (for prediction, already used)\")\n",
        "        print(\"   * **LLM Integration:** `langchain`, `llama_index` (these frameworks help build RAG pipelines). You'll also need a client library for your chosen LLM (e.g., `openai`, `google-generativeai`, `huggingface_hub`).\")\n",
        "        print(\"   * **Vector Databases (for external knowledge):** `chromadb`, `faiss-cpu`, `pinecone-client` (if you augment with external malaria documents).\")\n",
        "        print(\"   * **Chatbot Interface:** `streamlit`, `gradio`, or a simple `input()` loop for console-based.\")\n",
        "\n",
        "        print(\"\\n**PyCharm Setup Advice:**\")\n",
        "        print(\"1.  **Create a New Project:** Open PyCharm, select 'New Project'. Choose 'Pure Python' or 'Poetry Environment' for dependency management.\")\n",
        "        print(\"2.  **Install Libraries:** Open PyCharm's Terminal (View -> Tool Windows -> Terminal) and install necessary packages:\")\n",
        "        print(\"    `pip install pandas scikit-learn`\")\n",
        "        print(\"    `pip install langchain openai # or google-generativeai, huggingface_hub, etc.`\")\n",
        "        print(\"    `pip install streamlit # or gradio for UI`\")\n",
        "        print(\"3.  **Place Dataset:** Ensure `AfricaDataset.csv` is in your project's root directory or provide the full path.\")\n",
        "        print(\"4.  **Copy this Code:** Paste the provided Python code into a `.py` file (e.g., `malaria_chatbot.py`).\")\n",
        "        print(\"5.  **API Keys:** For LLMs, you'll need to set up environment variables for your API keys (e.g., `OPENAI_API_KEY`). PyCharm allows you to configure environment variables for run configurations.\")\n",
        "        print(\"6.  **Develop Iteratively:** Start with the data loading, then the prediction, then basic Q&A. Once these parts work, begin integrating `langchain` or `llama_index` to connect them with an LLM.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical methods"
      ],
      "metadata": {
        "id": "vsWI7S8ezh5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Show column names\n",
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "id": "XWfr2mH8q5s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Binomial GLM: Modeling malaria positives as a proportion of those examined\n",
        "model = smf.glm(\n",
        "    formula=\"Pf ~ Lat + Long + C(AREA_TYPE) + Year\",\n",
        "    data=df,\n",
        "    family=sm.families.Binomial(),\n",
        "    offset=np.log(df['Ex'])  # Ex = Examined count\n",
        ")\n",
        "result = model.fit()\n",
        "print(result.summary())\n"
      ],
      "metadata": {
        "id": "I4hJiE-1MrZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use logit model for proportion (make sure values are in (0,1), not 0 or 1 exactly)\n",
        "df = df[(df['prop_positive'] > 0) & (df['prop_positive'] < 1)]\n",
        "\n",
        "model = smf.glm(\n",
        "    formula=\"prop_positive ~ Lat + Long + C(AREA_TYPE) + Year\",\n",
        "    data=df,\n",
        "    family=sm.families.Binomial()\n",
        ")\n",
        "result = model.fit()\n",
        "print(result.summary())\n"
      ],
      "metadata": {
        "id": "MULXl8MtqGqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from patsy import dmatrix\n",
        "\n",
        "# Nonlinear spline for Year\n",
        "spline = dmatrix(\"bs(Year, df=5, degree=3)\", {\"Year\": df['Year']}, return_type='dataframe')\n",
        "df = df.join(spline)\n",
        "\n",
        "# Fit GAM-like GLM with spline\n",
        "model = sm.GLM(df[\"prop_positive\"], df[spline.columns.tolist() + ['Lat', 'Long']], family=sm.families.Binomial())\n",
        "result = model.fit()\n",
        "print(result.summary())\n"
      ],
      "metadata": {
        "id": "qMLvvcr1rKO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.discrete.discrete_model import NegativeBinomial\n",
        "\n",
        "model = smf.glm(\"Pf ~ Lat + Long + C(AREA_TYPE) + Year\", data=df,\n",
        "                family=sm.families.Poisson(), offset=np.log(df['Ex']))\n",
        "result = model.fit()\n",
        "print(result.summary())"
      ],
      "metadata": {
        "id": "qtpZlhFxrXpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['predicted'] = result.predict()\n",
        "plt.scatter(df['Year'], df['predicted'], alpha=0.3)\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Predicted Prevalence (logit)\")\n",
        "plt.title(\"Predicted Malaria Prevalence Over Time\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sq-q6CMurfjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only relevant columns\n",
        "df_model = df[['COUNTRY', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf']].dropna()\n",
        "\n",
        "# Convert categorical column\n",
        "df_model['COUNTRY'] = df_model['COUNTRY'].astype('category')"
      ],
      "metadata": {
        "id": "uubG2SqOrphL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode COUNTRY\n",
        "df_encoded = pd.get_dummies(df_model, columns=['COUNTRY'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "n4FFYr9cslWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_encoded.drop(columns=['Pf'])\n",
        "y = df_encoded['Pf']\n"
      ],
      "metadata": {
        "id": "3nAjKLzhsp2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Ys2EW66osr29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "poisson_model = sm.GLM(y_train, sm.add_constant(X_train), family=sm.families.Poisson())\n",
        "poisson_result = poisson_model.fit()\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_poisson = poisson_result.predict(sm.add_constant(X_test))\n"
      ],
      "metadata": {
        "id": "pV_NLPYHstvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm all columns are numeric\n",
        "print(X_train.dtypes)\n",
        "X_train = X_train.apply(pd.to_numeric)\n",
        "X_test = X_test.apply(pd.to_numeric)\n",
        "y_train = pd.to_numeric(y_train)\n",
        "y_test = pd.to_numeric(y_test)\n"
      ],
      "metadata": {
        "id": "_96wSgxrs-5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert boolean columns to integers (0 or 1)\n",
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)\n"
      ],
      "metadata": {
        "id": "27mc5yyhtjp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Add constant column\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# Fit Poisson regression\n",
        "poisson_model = sm.GLM(y_train, X_train_const, family=sm.families.Poisson())\n",
        "poisson_result = poisson_model.fit()\n",
        "\n",
        "# Predict\n",
        "y_pred_poisson = poisson_result.predict(X_test_const)\n",
        "\n",
        "# Evaluate\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"Poisson RMSE:\", mean_squared_error(y_test, y_pred_poisson))\n"
      ],
      "metadata": {
        "id": "zscPTkIgswhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------\n",
        "# 1. Load & Prepare Data\n",
        "# ---------------------\n",
        "df = pd.read_csv(\"/content/AfricaDataset.csv.csv\")\n",
        "\n",
        "# Keep only relevant columns\n",
        "df_model = df[['COUNTRY', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf']].dropna()\n",
        "\n",
        "# Filter invalid cases\n",
        "df_model = df_model[df_model['Ex'] > 0]\n",
        "df_model = df_model[df_model['Pf'] <= df_model['Ex']]\n",
        "\n",
        "# One-hot encode COUNTRY\n",
        "df_model['COUNTRY'] = df_model['COUNTRY'].astype(str)\n",
        "df_encoded = pd.get_dummies(df_model, columns=['COUNTRY'], drop_first=True)\n",
        "\n",
        "# Create features (X) and targets (y)\n",
        "X = df_encoded.drop(columns=['Pf'])\n",
        "y_success = df_encoded['Pf']\n",
        "y_trials = df_encoded['Ex']\n",
        "y_fail = y_trials - y_success\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_success_train, y_success_test, y_trials_train, y_trials_test = train_test_split(\n",
        "    X, y_success, y_trials, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Add constant\n",
        "X_train_const = sm.add_constant(X_train.astype(float))\n",
        "X_test_const = sm.add_constant(X_test.astype(float))\n",
        "\n",
        "# ---------------------\n",
        "# 2. Fit Models\n",
        "# ---------------------\n",
        "\n",
        "# --- Poisson Regression ---\n",
        "poisson_model = sm.GLM(y_success_train, X_train_const, family=sm.families.Poisson())\n",
        "poisson_result = poisson_model.fit()\n",
        "y_pred_poisson = poisson_result.predict(X_test_const)\n",
        "\n",
        "# --- Binomial Regression (NEW) ---\n",
        "# Combine successes and failures for binomial GLM\n",
        "y_binom_train = np.column_stack((y_success_train, y_trials_train - y_success_train))\n",
        "\n",
        "binom_model = sm.GLM(y_binom_train, X_train_const, family=sm.families.Binomial())\n",
        "binom_result = binom_model.fit()\n",
        "y_pred_binom = binom_result.predict(X_test_const) * y_trials_test  # convert probs to expected counts\n",
        "\n",
        "# --- Linear Regression ---\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_success_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# ---------------------\n",
        "# 3. Evaluate Models\n",
        "# ---------------------\n",
        "def evaluate_model(name, y_true, y_pred, result=None):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    print(f\"\\n {name} Model:\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    if result is not None:\n",
        "        print(f\"  AIC:  {result.aic:.2f}\")\n",
        "        print(f\"  BIC:  {result.bic:.2f}\")\n",
        "\n",
        "evaluate_model(\"Poisson\", y_success_test, y_pred_poisson, poisson_result)\n",
        "evaluate_model(\"Binomial\", y_success_test, y_pred_binom, binom_result)\n",
        "evaluate_model(\"Linear Regression\", y_success_test, y_pred_lr)\n",
        "\n",
        "# ---------------------\n",
        "# 4. Plot Actual vs Predicted\n",
        "# ---------------------\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(y_success_test, y_pred_poisson, alpha=0.3)\n",
        "plt.title(\"Poisson Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(y_success_test, y_pred_binom, alpha=0.3, color='green')\n",
        "plt.title(\"Binomial Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(y_success_test, y_pred_lr, alpha=0.3, color='red')\n",
        "plt.title(\"Linear Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zoi5A0j8s0ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dmD5u53vG1-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Keep relevant columns\n",
        "df_model = df[['Lat', 'Long', 'Ex', 'Pf']].dropna()\n",
        "df_model = df_model[df_model['Ex'] > 0]\n",
        "df_model = df_model[df_model['Pf'] <= df_model['Ex']]\n",
        "\n",
        "# Create features and target\n",
        "X = df_model[['Lat', 'Long']].astype(float)\n",
        "y_success = df_model['Pf'].astype(float)\n",
        "y_trials = df_model['Ex'].astype(float)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_success_train, y_success_test, y_trials_train, y_trials_test = train_test_split(\n",
        "    X, y_success, y_trials, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Add constant term\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# ---------------------\n",
        "# 2. Fit Models\n",
        "# ---------------------\n",
        "\n",
        "# --- Poisson Regression ---\n",
        "poisson_model = sm.GLM(y_success_train, X_train_const, family=sm.families.Poisson())\n",
        "poisson_result = poisson_model.fit()\n",
        "y_pred_poisson = poisson_result.predict(X_test_const)\n",
        "\n",
        "# --- Binomial Regression ---\n",
        "y_binom_train = np.column_stack((y_success_train, y_trials_train - y_success_train))\n",
        "\n",
        "binom_model = sm.GLM(y_binom_train, X_train_const, family=sm.families.Binomial())\n",
        "binom_result = binom_model.fit()\n",
        "y_pred_binom = binom_result.predict(X_test_const) * y_trials_test  # Convert probability to expected counts\n",
        "\n",
        "# --- Linear Regression ---\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_success_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# ---------------------\n",
        "# 3. Evaluate Models\n",
        "# ---------------------\n",
        "def evaluate_model(name, y_true, y_pred, result=None):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    print(f\"\\n {name} Model:\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    if result is not None:\n",
        "        print(f\"  AIC:  {result.aic:.2f}\")\n",
        "        print(f\"  BIC:  {result.bic:.2f}\")\n",
        "\n",
        "evaluate_model(\"Poisson\", y_success_test, y_pred_poisson, poisson_result)\n",
        "evaluate_model(\"Binomial\", y_success_test, y_pred_binom, binom_result)\n",
        "evaluate_model(\"Linear Regression\", y_success_test, y_pred_lr)\n",
        "\n",
        "# ---------------------\n",
        "# 4. Plot Actual vs Predicted\n",
        "# ---------------------\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(y_success_test, y_pred_poisson, alpha=0.3)\n",
        "plt.title(\"Poisson Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(y_success_test, y_pred_binom, alpha=0.3, color='green')\n",
        "plt.title(\"Binomial Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(y_success_test, y_pred_lr, alpha=0.3, color='red')\n",
        "plt.title(\"Linear Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fyru53Adt8nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"/content/AfricaDataset.csv.csv\")\n",
        "\n",
        "# Keep relevant columns\n",
        "df_model = df[['Lat', 'Long', 'Ex', 'Pf']].dropna()\n",
        "df_model = df_model[df_model['Ex'] > 0]\n",
        "df_model = df_model[df_model['Pf'] <= df_model['Ex']]\n",
        "\n",
        "# Create features and target\n",
        "X = df_model[['Lat', 'Long']].astype(float)\n",
        "y_success = df_model['Pf'].astype(float)\n",
        "y_trials = df_model['Ex'].astype(float)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_success_train, y_success_test, y_trials_train, y_trials_test = train_test_split(\n",
        "    X, y_success, y_trials, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Add constant term\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# ---------------------\n",
        "# 2. Fit Models\n",
        "# ---------------------\n",
        "\n",
        "# --- Poisson Regression ---\n",
        "poisson_model = sm.GLM(y_success_train, X_train_const, family=sm.families.Poisson())\n",
        "poisson_result = poisson_model.fit()\n",
        "y_pred_poisson = poisson_result.predict(X_test_const)\n",
        "\n",
        "# --- Binomial Regression ---\n",
        "y_binom_train = np.column_stack((y_success_train, y_trials_train - y_success_train))\n",
        "\n",
        "binom_model = sm.GLM(y_binom_train, X_train_const, family=sm.families.Binomial())\n",
        "binom_result = binom_model.fit()\n",
        "y_pred_binom = binom_result.predict(X_test_const) * y_trials_test  # Convert probability to expected counts\n",
        "\n",
        "# --- Linear Regression ---\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_success_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# ---------------------\n",
        "# 3. Evaluate Models\n",
        "# ---------------------\n",
        "def evaluate_model(name, y_true, y_pred, result=None):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
        "    print(f\"\\n {name} Model:\")\n",
        "    print(f\"  RMSE: {rmse:.4f}\")\n",
        "    print(f\"  MAE:  {mae:.4f}\")\n",
        "    print(f\" R2: {r2:.4f}\")\n",
        "    if result is not None:\n",
        "        print(f\"  AIC:  {result.aic:.2f}\")\n",
        "        print(f\"  BIC:  {result.bic:.2f}\")\n",
        "\n",
        "evaluate_model(\"Poisson\", y_success_test, y_pred_poisson, poisson_result)\n",
        "evaluate_model(\"Binomial\", y_success_test, y_pred_binom, binom_result)\n",
        "evaluate_model(\"Linear Regression\", y_success_test, y_pred_lr)\n",
        "\n",
        "# ---------------------\n",
        "# 4. Plot Actual vs Predicted\n",
        "# ---------------------\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(y_success_test, y_pred_poisson, alpha=0.3)\n",
        "plt.title(\"Poisson Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(y_success_test, y_pred_binom, alpha=0.3, color='green')\n",
        "plt.title(\"Binomial Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(y_success_test, y_pred_lr, alpha=0.3, color='red')\n",
        "plt.title(\"Linear Regression\")\n",
        "plt.xlabel(\"Actual Pf\")\n",
        "plt.ylabel(\"Predicted Pf\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IpCtlmdz_aSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_country_models(country_name, df):\n",
        "    import statsmodels.api as sm\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    import numpy as np\n",
        "\n",
        "    def evaluate_model(name, y_true, y_pred, result=None):\n",
        "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "        aic = result.aic if result else None\n",
        "        bic = result.bic if result else None\n",
        "        return {'Model': name, 'RMSE': rmse, 'MAE': mae, 'AIC': aic, 'BIC': bic}\n",
        "\n",
        "    results = []\n",
        "\n",
        "    df_c = df[df['COUNTRY'] == country_name].dropna()\n",
        "    df_c = df_c[(df_c['Ex'] > 0) & (df_c['Pf'] <= df_c['Ex'])]\n",
        "\n",
        "    if len(df_c) < 100:\n",
        "        print(f\"Skipping {country_name} due to insufficient data.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # ---------------- Temporal ----------------\n",
        "    X_temp = df_c[['YY', 'LoAge', 'UpAge', 'Ex']]\n",
        "    y_temp = df_c['Pf']\n",
        "    y_trials_temp = df_c['Ex']\n",
        "    y_fail_temp = y_trials_temp - y_temp\n",
        "\n",
        "    X_train, X_test, y_train, y_test, trials_train, trials_test = train_test_split(\n",
        "        X_temp, y_temp, y_trials_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "    X_train_const = sm.add_constant(X_train)\n",
        "    X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "    # Poisson\n",
        "    p_model = sm.GLM(y_train, X_train_const, family=sm.families.Poisson()).fit()\n",
        "    y_pred = p_model.predict(X_test_const)\n",
        "    results.append(evaluate_model('Poisson (Temporal)', y_test, y_pred, p_model))\n",
        "\n",
        "    # Binomial\n",
        "    y_bin = np.column_stack((y_train, trials_train - y_train))\n",
        "    b_model = sm.GLM(y_bin, X_train_const, family=sm.families.Binomial()).fit()\n",
        "    y_pred = b_model.predict(X_test_const) * trials_test\n",
        "    results.append(evaluate_model('Binomial (Temporal)', y_test, y_pred, b_model))\n",
        "\n",
        "    # Linear\n",
        "    lr = LinearRegression().fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    results.append(evaluate_model('Linear (Temporal)', y_test, y_pred))\n",
        "\n",
        "    # ---------------- Spatial ----------------\n",
        "    X_spatial = df_c[['Lat', 'Long']]\n",
        "    y_spatial = df_c['Pf']\n",
        "    y_trials_spatial = df_c['Ex']\n",
        "\n",
        "    X_train, X_test, y_train, y_test, trials_train, trials_test = train_test_split(\n",
        "        X_spatial, y_spatial, y_trials_spatial, test_size=0.2, random_state=42)\n",
        "\n",
        "    X_train_const = sm.add_constant(X_train)\n",
        "    X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "    # Poisson\n",
        "    p_model = sm.GLM(y_train, X_train_const, family=sm.families.Poisson()).fit()\n",
        "    y_pred = p_model.predict(X_test_const)\n",
        "    results.append(evaluate_model('Poisson (Spatial)', y_test, y_pred, p_model))\n",
        "\n",
        "    # Binomial\n",
        "    y_bin = np.column_stack((y_train, trials_train - y_train))\n",
        "    b_model = sm.GLM(y_bin, X_train_const, family=sm.families.Binomial()).fit()\n",
        "    y_pred = b_model.predict(X_test_const) * trials_test\n",
        "    results.append(evaluate_model('Binomial (Spatial)', y_test, y_pred, b_model))\n",
        "\n",
        "    # Linear\n",
        "    lr = LinearRegression().fit(X_train, y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    results.append(evaluate_model('Linear (Spatial)', y_test, y_pred))\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "ZS0dm9SYveLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "from statsmodels.genmod.generalized_linear_model import SET_USE_BIC_LLF\n",
        "\n",
        "# Optional: suppress BIC FutureWarnings and switch to log-likelihood-based BIC\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "SET_USE_BIC_LLF(True)\n",
        "\n",
        "# --- Helper Function: Model Evaluation for a Country ---\n",
        "def evaluate_country_models(country_name, df):\n",
        "    df_country = df[df['COUNTRY'] == country_name].copy()\n",
        "\n",
        "    # Drop missing values\n",
        "    df_country = df_country.dropna()\n",
        "\n",
        "    # Ensure enough data points\n",
        "    if len(df_country) < 50:\n",
        "        return pd.DataFrame()  # Skip small datasets\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Feature sets\n",
        "    temporal_cols = ['YY', 'LoAge', 'UpAge', 'Ex']\n",
        "    spatial_cols = ['Lat', 'Long']\n",
        "    target_col = 'Pf'\n",
        "\n",
        "    # ----------- TEMPORAL FEATURES -----------\n",
        "    X_temp = df_country[temporal_cols]\n",
        "    y_temp = df_country[target_col]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Linear Regression\n",
        "    lr = LinearRegression().fit(X_train, y_train)\n",
        "    y_pred_lr = lr.predict(X_test)\n",
        "    rmse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "    mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "    results.append({'Model': 'Linear Regression (Temporal)', 'RMSE': rmse_lr, 'MAE': mae_lr, 'AIC': None, 'BIC': None})\n",
        "\n",
        "    # Poisson Regression\n",
        "    poisson_model = sm.GLM(y_train, sm.add_constant(X_train), family=sm.families.Poisson())\n",
        "    poisson_result = poisson_model.fit()\n",
        "    y_pred_poisson = poisson_result.predict(sm.add_constant(X_test))\n",
        "    rmse_poisson = mean_squared_error(y_test, y_pred_poisson)\n",
        "    mae_poisson = mean_absolute_error(y_test, y_pred_poisson)\n",
        "    results.append({'Model': 'Poisson (Temporal)', 'RMSE': rmse_poisson, 'MAE': mae_poisson,\n",
        "                    'AIC': poisson_result.aic, 'BIC': poisson_result.bic_llf})\n",
        "\n",
        "    # Binomial Regression (must convert target to probability [0,1])\n",
        "    y_bin = np.clip(y_train / (y_train.max() + 1), 0, 1)\n",
        "    binomial_model = sm.GLM(y_bin, sm.add_constant(X_train), family=sm.families.Binomial())\n",
        "    binomial_result = binomial_model.fit()\n",
        "    y_pred_binomial = binomial_result.predict(sm.add_constant(X_test))\n",
        "    y_pred_binomial = y_pred_binomial * (y_train.max() + 1)  # scale back\n",
        "    rmse_bin = mean_squared_error(y_test, y_pred_binomial)\n",
        "    mae_bin = mean_absolute_error(y_test, y_pred_binomial)\n",
        "    results.append({'Model': 'Binomial (Temporal)', 'RMSE': rmse_bin, 'MAE': mae_bin,\n",
        "                    'AIC': binomial_result.aic, 'BIC': binomial_result.bic_llf})\n",
        "\n",
        "    # ----------- SPATIAL FEATURES -----------\n",
        "    X_spatial = df_country[spatial_cols]\n",
        "    y_spatial = df_country[target_col]\n",
        "\n",
        "    X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_spatial, y_spatial, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Linear Regression (Spatial)\n",
        "    lr_s = LinearRegression().fit(X_train_s, y_train_s)\n",
        "    y_pred_lr_s = lr_s.predict(X_test_s)\n",
        "    rmse_lr_s = mean_squared_error(y_test_s, y_pred_lr_s)\n",
        "    mae_lr_s = mean_absolute_error(y_test_s, y_pred_lr_s)\n",
        "    results.append({'Model': 'Linear Regression (Spatial)', 'RMSE': rmse_lr_s, 'MAE': mae_lr_s, 'AIC': None, 'BIC': None})\n",
        "\n",
        "    # Poisson (Spatial)\n",
        "    poisson_model_s = sm.GLM(y_train_s, sm.add_constant(X_train_s), family=sm.families.Poisson())\n",
        "    poisson_result_s = poisson_model_s.fit()\n",
        "    y_pred_poisson_s = poisson_result_s.predict(sm.add_constant(X_test_s))\n",
        "    rmse_poisson_s = mean_squared_error(y_test_s, y_pred_poisson_s)\n",
        "    mae_poisson_s = mean_absolute_error(y_test_s, y_pred_poisson_s)\n",
        "    results.append({'Model': 'Poisson (Spatial)', 'RMSE': rmse_poisson_s, 'MAE': mae_poisson_s,\n",
        "                    'AIC': poisson_result_s.aic, 'BIC': poisson_result_s.bic_llf})\n",
        "\n",
        "    # Binomial (Spatial)\n",
        "    y_bin_s = np.clip(y_train_s / (y_train_s.max() + 1), 0, 1)\n",
        "    binomial_model_s = sm.GLM(y_bin_s, sm.add_constant(X_train_s), family=sm.families.Binomial())\n",
        "    binomial_result_s = binomial_model_s.fit()\n",
        "    y_pred_binomial_s = binomial_result_s.predict(sm.add_constant(X_test_s))\n",
        "    y_pred_binomial_s = y_pred_binomial_s * (y_train_s.max() + 1)\n",
        "    rmse_bin_s = mean_squared_error(y_test_s, y_pred_binomial_s)\n",
        "    mae_bin_s = mean_absolute_error(y_test_s, y_pred_binomial_s)\n",
        "    results.append({'Model': 'Binomial (Spatial)', 'RMSE': rmse_bin_s, 'MAE': mae_bin_s,\n",
        "                    'AIC': binomial_result_s.aic, 'BIC': binomial_result_s.bic_llf})\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "df_all = df.copy()\n",
        "\n",
        "# Ensure proper columns\n",
        "df_all = df_all[['COUNTRY', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'Lat', 'Long']]\n",
        "df_all = df_all.dropna()\n",
        "\n",
        "# List of countries to test\n",
        "countries = df_all['COUNTRY'].value_counts().index.tolist()\n",
        "\n",
        "final_results = []\n",
        "\n",
        "for country in countries:\n",
        "    print(f\"\\n📍 Running for {country}\")\n",
        "    res = evaluate_country_models(country, df_all)\n",
        "    if not res.empty:\n",
        "        res['Country'] = country\n",
        "        final_results.append(res)\n",
        "\n",
        "# Combine all results\n",
        "df_summary = pd.concat(final_results, ignore_index=True)\n",
        "\n",
        "# Optional: Save results\n",
        "# df_summary.to_csv(\"country_model_comparison.csv\", index=False)\n",
        "\n",
        "# Display top results\n",
        "print(\"\\n📊 Top 10 model performances:\")\n",
        "display(df_summary.sort_values(by=\"RMSE\").head(10))\n"
      ],
      "metadata": {
        "id": "Gx2T2mz5wAXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly\n"
      ],
      "metadata": {
        "id": "3du-mG4BwGZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Aggregate RMSE for a specific model (e.g., Binomial Temporal)\n",
        "df_heat = df_summary[df_summary['Model'] == 'Binomial (Temporal)'][['Country', 'RMSE']].copy()\n",
        "df_heat['Country'] = df_heat['Country'].str.strip()\n",
        "\n",
        "# Plot\n",
        "fig = px.choropleth(\n",
        "    df_heat,\n",
        "    locations='Country',\n",
        "    locationmode='country names',\n",
        "    color='RMSE',\n",
        "    color_continuous_scale='YlOrRd',\n",
        "    title=' RMSE for Binomial (Temporal) Model by Country',\n",
        "    labels={'RMSE': 'RMSE'}\n",
        ")\n",
        "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "eKC_Xhrqwc0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df has columns: Pf, Ex, COUNTRY\n",
        "\n",
        "with pm.Model() as model:\n",
        "    # Hyperpriors for group-level variation\n",
        "    alpha = pm.HalfNormal(\"alpha\", sigma=5)\n",
        "    beta = pm.HalfNormal(\"beta\", sigma=5)\n",
        "\n",
        "    # Expected probability for each data point\n",
        "    theta = pm.Beta(\"theta\", alpha=alpha, beta=beta, shape=df.shape[0])\n",
        "\n",
        "    # Observed data\n",
        "    pf_obs = pm.Binomial(\"obs\", n=df['Ex'].values, p=theta, observed=df['Pf'].values)\n",
        "\n",
        "    trace = pm.sample(300, tune=300, target_accept=0.9, random_seed=42)\n",
        "    pm.summary(trace)\n"
      ],
      "metadata": {
        "id": "04jsDks-wtRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymc as pm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assume df has columns: Pf, Ex, COUNTRY\n",
        "df = df.dropna(subset=['Pf', 'Ex', 'COUNTRY'])\n",
        "df['country_id'] = df['COUNTRY'].astype('category').cat.codes\n",
        "\n",
        "n_countries = df['country_id'].nunique()\n",
        "\n",
        "with pm.Model() as hierarchical_binomial:\n",
        "    # Hyperpriors\n",
        "    mu_a = pm.Normal('mu_a', 0, 2)\n",
        "    sigma_a = pm.Exponential('sigma_a', 1)\n",
        "\n",
        "    # Country-level random intercepts (logit-scale)\n",
        "    a = pm.Normal('a', mu=mu_a, sigma=sigma_a, shape=n_countries)\n",
        "\n",
        "    # Linear predictor (logit link)\n",
        "    logit_p = a[df['country_id'].values]\n",
        "    p = pm.Deterministic('p', pm.math.sigmoid(logit_p))\n",
        "\n",
        "    # Likelihood\n",
        "    y_obs = pm.Binomial('y_obs', n=df['Ex'].values, p=p, observed=df['Pf'].values)\n",
        "\n",
        "    trace = pm.sample(300, tune=300, target_accept=0.9, random_seed=42)\n",
        "    pm.summary(trace, var_names=['mu_a', 'sigma_a'])\n"
      ],
      "metadata": {
        "id": "N7NNo5oh02gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " pm.summary(trace, var_names=['mu_a', 'sigma_a'])"
      ],
      "metadata": {
        "id": "yM_IYG7d1wHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import arviz as az\n",
        "\n",
        "country_probs = trace.posterior['p'].mean(dim=[\"chain\", \"draw\"]).values\n",
        "df['posterior_mean_p'] = country_probs\n",
        "\n",
        "# Show top countries\n",
        "print(df[['COUNTRY', 'posterior_mean_p']].groupby('COUNTRY').mean().sort_values(by='posterior_mean_p', ascending=False))\n"
      ],
      "metadata": {
        "id": "4-Ro85tYM14k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az.plot_posterior(trace, var_names=[\"mu_a\", \"sigma_a\"], hdi_prob=0.95)\n"
      ],
      "metadata": {
        "id": "xjnSzkiVNJNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mean_probs = df.groupby('COUNTRY')['posterior_mean_p'].mean().sort_values()\n",
        "plt.figure(figsize=(10,6))\n",
        "mean_probs.plot(kind='barh')\n",
        "plt.xlabel(\"Estimated Malaria Prevalence\")\n",
        "plt.title(\"Posterior Mean Prevalence by Country\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "U8JR2PxqNMbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymc as pm\n",
        "import arviz as az\n",
        "\n",
        "# Step 1: Filter for one country — say, Tanzania\n",
        "df_tz = df[df[\"COUNTRY\"] == \"Tanzania\"].copy()\n",
        "\n",
        "# Step 2: Add fake climate features — Temperature and Humidity\n",
        "np.random.seed(42)  # for reproducibility\n",
        "df_tz[\"Temperature\"] = np.random.normal(loc=27, scale=2, size=len(df_tz))  # typical tropical temps\n",
        "df_tz[\"Humidity\"] = np.random.uniform(low=60, high=90, size=len(df_tz))    # typical high humidity\n",
        "\n",
        "# Step 3: Clean the data — drop missing\n",
        "df_tz = df_tz.dropna(subset=[\"Pf\", \"Ex\", \"Temperature\", \"Humidity\"])\n",
        "\n",
        "# Step 4: Fit a binomial model with climate covariates\n",
        "with pm.Model() as climate_model:\n",
        "    # Priors for coefficients\n",
        "    intercept = pm.Normal(\"intercept\", mu=0, sigma=2)\n",
        "    beta_temp = pm.Normal(\"beta_temp\", mu=0, sigma=1)\n",
        "    beta_humid = pm.Normal(\"beta_humid\", mu=0, sigma=1)\n",
        "\n",
        "    # Linear model\n",
        "    logit_p = (\n",
        "        intercept\n",
        "        + beta_temp * df_tz[\"Temperature\"].values\n",
        "        + beta_humid * df_tz[\"Humidity\"].values\n",
        "    )\n",
        "    p = pm.Deterministic(\"p\", pm.math.sigmoid(logit_p))\n",
        "\n",
        "    # Likelihood\n",
        "    y_obs = pm.Binomial(\"y_obs\", n=df_tz[\"Ex\"].values, p=p, observed=df_tz[\"Pf\"].values)\n",
        "\n",
        "    # Sample from posterior\n",
        "    trace_climate = pm.sample(1000, tune=1000, target_accept=0.9, random_seed=42)\n"
      ],
      "metadata": {
        "id": "rl3gaPpvNVuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  pymc"
      ],
      "metadata": {
        "id": "_RO2DdOya58W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xNd6dhu6b53J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}