{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#DL"
      ],
      "metadata": {
        "id": "wnYlWxwN_Ho1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ZIM_clinic_data - ZIM_clinic_data.csv.csv')\n",
        "\n",
        "# Display the first 5 rows and column information\n",
        "print(df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "oMHnJD7c_Js_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ZIM_clinic_data - ZIM_clinic_data.csv.csv')\n",
        "\n",
        "# Prepare data for classification\n",
        "df_classification = df.dropna(subset=['mainlander_on_zb']).copy()\n",
        "\n",
        "features = ['agegroup', 'sex', 'occupation', 'home_district', 'travel', 'travel_over_4_nights', 'travel_over_14_nights']\n",
        "target = 'mainlander_on_zb'\n",
        "\n",
        "X = df_classification[features]\n",
        "y = df_classification[target]\n",
        "\n",
        "categorical_features = ['agegroup', 'sex', 'occupation', 'home_district']\n",
        "numerical_features = ['travel', 'travel_over_4_nights', 'travel_over_14_nights']\n",
        "\n",
        "# Impute missing values\n",
        "for col in numerical_features:\n",
        "    X[col] = X[col].fillna(X[col].mean())\n",
        "for col in categorical_features:\n",
        "    X[col] = X[col].fillna(X[col].mode()[0])\n",
        "\n",
        "# Preprocessing: One-hot encode categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train a deep learning model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Tabular Classification Model Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "i39prs4U_KrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ZIM_clinic_data - ZIM_clinic_data.csv.csv')\n",
        "\n",
        "# Prepare data for time series analysis\n",
        "df_ts = df.copy()\n",
        "df_ts['date'] = pd.to_datetime(df_ts['date'], format='%Y-%m')\n",
        "travelers_by_month = df_ts.groupby('date')['travel'].sum().reset_index()\n",
        "\n",
        "# Prepare data for LSTM model\n",
        "def create_sequences(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix > len(data) - 1:\n",
        "            break\n",
        "        seq_x, seq_y = data[i:end_ix], data[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "n_steps = 3  # Use the last 3 months to predict the next\n",
        "X_ts, y_ts = create_sequences(travelers_by_month['travel'].values, n_steps)\n",
        "X_ts = X_ts.reshape((X_ts.shape[0], X_ts.shape[1], 1))\n",
        "\n",
        "# Split into train/test\n",
        "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(X_ts, y_ts, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train an LSTM model\n",
        "model_ts = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(n_steps, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "model_ts.compile(optimizer='adam', loss='mse')\n",
        "model_ts.fit(X_train_ts, y_train_ts, epochs=200, verbose=1)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_ts = model_ts.predict(X_test_ts, verbose=0)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test_ts, y_pred_ts)\n",
        "print(f\"Time Series Forecasting Model MSE: {mse:.4f}\")"
      ],
      "metadata": {
        "id": "zw47Xqg1_a_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ZIM_clinic_data - ZIM_clinic_data.csv.csv')\n",
        "\n",
        "# Prepare data for entity embeddings\n",
        "df_embeddings = df.copy().dropna(subset=['occupation', 'mainlander_on_zb'])\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_embeddings['occupation_encoded'] = le.fit_transform(df_embeddings['occupation'])\n",
        "\n",
        "vocab_size = len(le.classes_)\n",
        "\n",
        "X_emb = df_embeddings['occupation_encoded']\n",
        "y_emb = df_embeddings['mainlander_on_zb']\n",
        "\n",
        "# Build a model with an embedding layer\n",
        "embedding_dim = 5\n",
        "model_emb = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name='occupation_embedding'),\n",
        "    Flatten(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_emb.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_emb.fit(X_emb, y_emb, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Extract embeddings\n",
        "occupation_embeddings = model_emb.get_layer('occupation_embedding').get_weights()[0]\n",
        "embeddings_df = pd.DataFrame(occupation_embeddings, index=le.classes_)\n",
        "print(\"Entity Embeddings for 'occupation' (first 5 rows):\\n\")\n",
        "print(embeddings_df.head())"
      ],
      "metadata": {
        "id": "w00zSyAo_pi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Data Preparation (Re-running from previous steps) ---\n",
        "df = pd.read_csv('ZIM_clinic_data - ZIM_clinic_data.csv.csv')\n",
        "\n",
        "# --- Tabular Classification Plots ---\n",
        "# Prepare data\n",
        "df_classification = df.dropna(subset=['mainlander_on_zb']).copy()\n",
        "features = ['agegroup', 'sex', 'occupation', 'home_district', 'travel', 'travel_over_4_nights', 'travel_over_14_nights']\n",
        "target = 'mainlander_on_zb'\n",
        "X = df_classification[features]\n",
        "y = df_classification[target]\n",
        "categorical_features = ['agegroup', 'sex', 'occupation', 'home_district']\n",
        "numerical_features = ['travel', 'travel_over_4_nights', 'travel_over_14_nights']\n",
        "for col in numerical_features:\n",
        "    X[col] = X[col].fillna(X[col].mean())\n",
        "for col in categorical_features:\n",
        "    X[col] = X[col].fillna(X[col].mode()[0])\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
        "y_pred_class = (model.predict(X_test, verbose=0) > 0.5).astype(\"int32\")\n",
        "cm = confusion_matrix(y_test, y_pred_class)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Mainlander', 'Mainlander'], yticklabels=['Non-Mainlander', 'Mainlander'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Time Series Analysis Plots ---\n",
        "# Prepare data\n",
        "df_ts = df.copy()\n",
        "df_ts['date'] = pd.to_datetime(df_ts['date'], format='%Y-%m')\n",
        "travelers_by_month = df_ts.groupby('date')['travel'].sum().reset_index()\n",
        "def create_sequences(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix > len(data) - 1:\n",
        "            break\n",
        "        seq_x, seq_y = data[i:end_ix], data[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "n_steps = 3\n",
        "X_ts, y_ts = create_sequences(travelers_by_month['travel'].values, n_steps)\n",
        "X_ts = X_ts.reshape((X_ts.shape[0], X_ts.shape[1], 1))\n",
        "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(X_ts, y_ts, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train model\n",
        "model_ts = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(n_steps, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "model_ts.compile(optimizer='adam', loss='mse')\n",
        "model_ts.fit(X_train_ts, y_train_ts, epochs=200, verbose=0)\n",
        "y_pred_ts = model_ts.predict(X_test_ts, verbose=0)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(travelers_by_month['date'].iloc[len(travelers_by_month) - len(y_test_ts):], y_test_ts, label='Actual Travelers', marker='o')\n",
        "plt.plot(travelers_by_month['date'].iloc[len(travelers_by_month) - len(y_test_ts):], y_pred_ts, label='Predicted Travelers', marker='x')\n",
        "plt.title('Time Series Forecasting: Actual vs. Predicted')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Travelers')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- Entity Embeddings Plots ---\n",
        "# Prepare data\n",
        "df_embeddings = df.copy().dropna(subset=['occupation', 'mainlander_on_zb'])\n",
        "le = LabelEncoder()\n",
        "df_embeddings['occupation_encoded'] = le.fit_transform(df_embeddings['occupation'])\n",
        "vocab_size = len(le.classes_)\n",
        "X_emb = df_embeddings['occupation_encoded']\n",
        "y_emb = df_embeddings['mainlander_on_zb']\n",
        "\n",
        "# Build and train model\n",
        "embedding_dim = 5\n",
        "model_emb = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=1, name='occupation_embedding'),\n",
        "    Flatten(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model_emb.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_emb.fit(X_emb, y_emb, epochs=10, batch_size=32, verbose=0)\n",
        "occupation_embeddings = model_emb.get_layer('occupation_embedding').get_weights()[0]\n",
        "\n",
        "# Plotting with PCA\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(occupation_embeddings)\n",
        "embeddings_df = pd.DataFrame(embeddings_2d, columns=['PC1', 'PC2'])\n",
        "embeddings_df['occupation'] = le.classes_\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.scatter(embeddings_df['PC1'], embeddings_df['PC2'])\n",
        "for i, txt in enumerate(embeddings_df['occupation']):\n",
        "    plt.annotate(txt, (embeddings_df['PC1'][i] + 0.01, embeddings_df['PC2'][i] + 0.01), fontsize=8)\n",
        "plt.title('2D PCA of Occupation Embeddings')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HhRg1_wk_5Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1EXdBsxw_aK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yiRiA3r8xDhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DL on Africa"
      ],
      "metadata": {
        "id": "XP9Bo7YBD-62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "\n",
        "# Drop irrelevant columns and those with all null values\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "\n",
        "# Features and target\n",
        "features = ['COUNTRY', 'Lat', 'Long', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "target = 'PfPR2-10'\n",
        "\n",
        "X_reg = df[features]\n",
        "y_reg = df[target]\n",
        "\n",
        "# Identify categorical and numerical features\n",
        "categorical_features_reg = ['COUNTRY', 'METHOD']\n",
        "\n",
        "# Create a preprocessor for one-hot encoding\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_reg)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply preprocessing\n",
        "X_train_processed_reg = preprocessor.fit_transform(X_train_reg)\n",
        "X_test_processed_reg = preprocessor.transform(X_test_reg)\n",
        "\n",
        "# Build a feedforward neural network\n",
        "model_reg = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_processed_reg.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Linear activation for regression\n",
        "])\n",
        "\n",
        "model_reg.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model_reg.fit(X_train_processed_reg, y_train_reg, epochs=10, batch_size=64, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss_reg, mae_reg = model_reg.evaluate(X_test_processed_reg, y_test_reg, verbose=0)\n",
        "print(f\"Regression Model Mean Absolute Error (MAE): {mae_reg:.4f}\")"
      ],
      "metadata": {
        "id": "W0DKVDjDCVn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "\n",
        "# Drop irrelevant columns\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "\n",
        "# Filter data for one country and aggregate by month\n",
        "df_ts = df[df['COUNTRY'] == 'Angola'].copy()\n",
        "df_ts['date'] = pd.to_datetime(df_ts['YY'].astype(str) + '-' + df_ts['MM'].astype(str))\n",
        "monthly_data = df_ts.groupby('date')['PfPR2-10'].mean().reset_index()\n",
        "\n",
        "# Prepare data for LSTM model\n",
        "def create_sequences(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data)):\n",
        "        end_ix = i + n_steps\n",
        "        if end_ix > len(data) - 1:\n",
        "            break\n",
        "        seq_x, seq_y = data[i:end_ix], data[end_ix]\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "n_steps = 12  # Use the last 12 months to predict the next\n",
        "X_ts, y_ts = create_sequences(monthly_data['PfPR2-10'].values, n_steps)\n",
        "X_ts = X_ts.reshape((X_ts.shape[0], X_ts.shape[1], 1))\n",
        "\n",
        "# Split into train/test\n",
        "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(X_ts, y_ts, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train an LSTM model\n",
        "model_ts = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(n_steps, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "model_ts.compile(optimizer='adam', loss='mse')\n",
        "model_ts.fit(X_train_ts, y_train_ts, epochs=100, verbose=0)\n",
        "\n",
        "# Make predictions and evaluate\n",
        "y_pred_ts = model_ts.predict(X_test_ts, verbose=0)\n",
        "mse_ts = mean_squared_error(y_test_ts, y_pred_ts)\n",
        "print(f\"Time Series Forecasting Model MSE: {mse_ts:.4f}\")"
      ],
      "metadata": {
        "id": "hJ7HR3hlEG4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "\n",
        "# Drop irrelevant columns and those with all null values\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "\n",
        "# Features including geographical data\n",
        "features_geo = ['Lat', 'Long', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "target = 'PfPR2-10'\n",
        "\n",
        "X_geo = df[features_geo]\n",
        "y_geo = df[target]\n",
        "\n",
        "# Identify categorical features for preprocessing\n",
        "categorical_features_geo = ['METHOD']\n",
        "\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Build a feedforward neural network\n",
        "model_geo = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model_geo.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model_geo.fit(X_train_processed_geo, y_train_geo, epochs=10, batch_size=64, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss_geo, mae_geo = model_geo.evaluate(X_test_processed_geo, y_test_geo, verbose=0)\n",
        "print(f\"Geospatial Regression Model Mean Absolute Error (MAE): {mae_geo:.4f}\")"
      ],
      "metadata": {
        "id": "WoJBuHsQEQVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Visualize Predicted PfPR2-10 on a Map ---\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "features_geo = ['Lat', 'Long', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features_geo]\n",
        "y_geo = df[target]\n",
        "categorical_features_geo = ['METHOD']\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Re-run the geospatial regression model to get predictions\n",
        "model_geo = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "model_geo.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "model_geo.fit(X_train_processed_geo, y_train_geo, epochs=10, batch_size=64, verbose=0)\n",
        "y_pred_geo = model_geo.predict(X_test_processed_geo, verbose=0)\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "plot_df = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df['Actual'] = y_test_geo.values\n",
        "plot_df['Predicted'] = y_pred_geo\n",
        "\n",
        "# Create the map plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.scatter(x=plot_df['Long'], y=plot_df['Lat'], c=plot_df['Predicted'], cmap='viridis', s=10, alpha=0.7)\n",
        "plt.scatter(x=plot_df['Long'], y=plot_df['Lat'], c=plot_df['Actual'], cmap='viridis', s=10, alpha=0.7)\n",
        "plt.colorbar(label='Predicted PfPR2-10')\n",
        "plt.title('Predicted PfPR2-10 Values on a Map')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 2. Spatial Feature Engineering and New Model ---\n",
        "\n",
        "print(\"\\n### Geospatial Regression with Advanced Spatial Features\\n\")\n",
        "\n",
        "# Add new spatial features to the dataset\n",
        "df['Lat_sq'] = df['Lat']**2\n",
        "df['Long_sq'] = df['Long']**2\n",
        "df['Lat_Long_inter'] = df['Lat'] * df['Long']\n",
        "\n",
        "# Define new features\n",
        "features_geo_adv = ['Lat', 'Long', 'Lat_sq', 'Long_sq', 'Lat_Long_inter', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "X_geo_adv = df[features_geo_adv]\n",
        "y_geo_adv = df[target]\n",
        "categorical_features_geo_adv = ['METHOD']\n",
        "preprocessor_geo_adv = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo_adv)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train_geo_adv, X_test_geo_adv, y_train_geo_adv, y_test_geo_adv = train_test_split(X_geo_adv, y_geo_adv, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo_adv = preprocessor_geo_adv.fit_transform(X_train_geo_adv)\n",
        "X_test_processed_geo_adv = preprocessor_geo_adv.transform(X_test_geo_adv)\n",
        "\n",
        "# Build a new feedforward neural network\n",
        "model_geo_adv = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_processed_geo_adv.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model_geo_adv.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the new model\n",
        "model_geo_adv.fit(X_train_processed_geo_adv, y_train_geo_adv, epochs=10, batch_size=64, verbose=0)\n",
        "\n",
        "# Evaluate the new model\n",
        "loss_geo_adv, mae_geo_adv = model_geo_adv.evaluate(X_test_processed_geo_adv, y_test_geo_adv, verbose=0)\n",
        "print(f\"Geospatial Regression Model with Advanced Features Mean Absolute Error (MAE): {mae_geo_adv:.4f}\")"
      ],
      "metadata": {
        "id": "Hs4e2EBXEbI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "features_geo = ['Lat', 'Long', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features_geo]\n",
        "y_geo = df[target]\n",
        "categorical_features_geo = ['METHOD']\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Re-run the geospatial regression model to get predictions\n",
        "model_geo = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "model_geo.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "model_geo.fit(X_train_processed_geo, y_train_geo, epochs=10, batch_size=64, verbose=0)\n",
        "y_pred_geo = model_geo.predict(X_test_processed_geo, verbose=0)\n",
        "\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "plot_df = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df['Actual'] = y_test_geo.values\n",
        "plot_df['Predicted'] = y_pred_geo\n",
        "\n",
        "# Create a single plot with two subplots for comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Plot actual values\n",
        "scatter_actual = axes[0].scatter(x=plot_df['Long'], y=plot_df['Lat'], c=plot_df['Actual'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[0].set_title('Actual PfPR2-10 Values')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "axes[0].grid(True)\n",
        "fig.colorbar(scatter_actual, ax=axes[0], label='Actual PfPR2-10')\n",
        "\n",
        "# Plot predicted values\n",
        "scatter_predicted = axes[1].scatter(x=plot_df['Long'], y=plot_df['Lat'], c=plot_df['Predicted'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[1].set_title('Predicted PfPR2-10 Values')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "axes[1].grid(True)\n",
        "fig.colorbar(scatter_predicted, ax=axes[1], label='Predicted PfPR2-10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lloHFk5YFI7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "features_geo = ['Lat', 'Long', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features_geo]\n",
        "y_geo = df[target]\n",
        "categorical_features_geo = ['METHOD']\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Re-run the geospatial regression model to get predictions\n",
        "model_geo = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "model_geo.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "model_geo.fit(X_train_processed_geo, y_train_geo, epochs=10, batch_size=64, verbose=0)\n",
        "y_pred_geo = model_geo.predict(X_test_processed_geo, verbose=0)\n",
        "\n",
        "mae = mean_absolute_error(y_test_geo, y_pred_geo)\n",
        "r2 = r2_score(y_test_geo, y_pred_geo)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_geo, y_pred_geo))\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "# Create a DataFrame for plotting\n",
        "plot_df = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df['Actual'] = y_test_geo.values\n",
        "plot_df['Predicted'] = y_pred_geo\n",
        "\n",
        "# Create a single plot with two subplots for comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Plot actual values\n",
        "scatter_actual = axes[0].scatter(x=plot_df['Long'], y=plot_df['Lat'], c=plot_df['Actual'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[0].set_title('Actual PfPR2-10 Values')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "axes[0].grid(True)\n",
        "fig.colorbar(scatter_actual, ax=axes[0], label='Actual PfPR2-10')\n",
        "\n",
        "# Plot predicted values\n",
        "scatter_predicted = axes[1].scatter(x=plot_df['Long'], y=plot_df['Lat'], c=plot_df['Predicted'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[1].set_title('Predicted PfPR2-10 Values')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "axes[1].grid(True)\n",
        "fig.colorbar(scatter_predicted, ax=axes[1], label='Predicted PfPR2-10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hx5jPiF6Hk7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "\n",
        "# Create new feature: distance to the equator\n",
        "df['dist_to_equator'] = np.abs(df['Lat'])\n",
        "\n",
        "# Features and target\n",
        "features = ['COUNTRY', 'Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features]\n",
        "y_geo = df[target]\n",
        "\n",
        "# Identify categorical and numerical features for the pipeline\n",
        "categorical_features_geo = ['COUNTRY', 'METHOD']\n",
        "numerical_features_geo = ['Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf']\n",
        "\n",
        "# Create a preprocessing pipeline with scaling and one-hot encoding\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_geo),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)\n",
        "    ])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply preprocessing to training and testing sets\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Build a new feedforward neural network with increased capacity\n",
        "model_geo_tuned = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model with MAE as the loss function\n",
        "model_geo_tuned.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "# Train the new model\n",
        "history = model_geo_tuned.fit(X_train_processed_geo, y_train_geo, epochs=20, batch_size=64, verbose=1)\n",
        "\n",
        "# Evaluate the new model\n",
        "loss_geo_tuned, mae_geo_tuned = model_geo_tuned.evaluate(X_test_processed_geo, y_test_geo, verbose=0)\n",
        "print(f\"Geospatial Regression Model with Tuned Features and Architecture Mean Absolute Error (MAE): {mae_geo_tuned:.4f}\")\n",
        "\n",
        "# Generate predictions for plotting\n",
        "y_pred_geo_tuned = model_geo_tuned.predict(X_test_processed_geo, verbose=0)\n",
        "\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "plot_df_tuned = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df_tuned['Actual'] = y_test_geo.values\n",
        "plot_df_tuned['Predicted'] = y_pred_geo_tuned\n",
        "\n",
        "# Create a single plot with two subplots for comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Plot actual values\n",
        "scatter_actual = axes[0].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Actual'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[0].set_title('Actual PfPR2-10 Values')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "axes[0].grid(True)\n",
        "fig.colorbar(scatter_actual, ax=axes[0], label='Actual PfPR2-10')\n",
        "\n",
        "# Plot predicted values\n",
        "scatter_predicted = axes[1].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Predicted'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[1].set_title('Predicted PfPR2-10 Values')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "axes[1].grid(True)\n",
        "fig.colorbar(scatter_predicted, ax=axes[1], label='Predicted PfPR2-10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x-P7VMdDGdp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "\n",
        "# Create new feature: distance to the equator\n",
        "df['dist_to_equator'] = np.abs(df['Lat'])\n",
        "\n",
        "# Features and target\n",
        "features = ['COUNTRY', 'Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features]\n",
        "y_geo = df[target]\n",
        "\n",
        "# Identify categorical and numerical features for the pipeline\n",
        "categorical_features_geo = ['COUNTRY', 'METHOD']\n",
        "numerical_features_geo = ['Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf']\n",
        "\n",
        "# Create a preprocessing pipeline with scaling and one-hot encoding\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_geo),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)\n",
        "    ])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply preprocessing to training and testing sets\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Build a new feedforward neural network with increased capacity\n",
        "model_geo_tuned = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model with MAE as the loss function\n",
        "model_geo_tuned.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
        "\n",
        "# Train the new model\n",
        "history = model_geo_tuned.fit(X_train_processed_geo, y_train_geo, epochs=20, batch_size=64, verbose=1)\n",
        "\n",
        "# Evaluate the new model\n",
        "loss_geo_tuned, mae_geo_tuned = model_geo_tuned.evaluate(X_test_processed_geo, y_test_geo, verbose=0)\n",
        "print(f\"Geospatial Regression Model with Tuned Features and Architecture Mean Absolute Error (MAE): {mae_geo_tuned:.4f}\")\n",
        "\n",
        "# Generate predictions for plotting\n",
        "y_pred_geo_tuned = model_geo_tuned.predict(X_test_processed_geo, verbose=0)\n",
        "\n",
        "# Calculate and print the metrics\n",
        "mae = mean_absolute_error(y_test_geo, y_pred_geo_tuned)\n",
        "r2 = r2_score(y_test_geo, y_pred_geo_tuned)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_geo, y_pred_geo_tuned))\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "plot_df_tuned = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df_tuned['Actual'] = y_test_geo.values\n",
        "plot_df_tuned['Predicted'] = y_pred_geo_tuned\n",
        "\n",
        "# Create a single plot with two subplots for comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Plot actual values\n",
        "scatter_actual = axes[0].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Actual'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[0].set_title('Actual PfPR2-10 Values')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "axes[0].grid(True)\n",
        "fig.colorbar(scatter_actual, ax=axes[0], label='Actual PfPR2-10')\n",
        "\n",
        "# Plot predicted values\n",
        "scatter_predicted = axes[1].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Predicted'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[1].set_title('Predicted PfPR2-10 Values')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "axes[1].grid(True)\n",
        "fig.colorbar(scatter_predicted, ax=axes[1], label='Predicted PfPR2-10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GQ0q_5tuGTeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame for plotting errors\n",
        "plot_df_errors = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df_errors['Error'] = y_test_geo.values - y_pred_geo_tuned.flatten()\n",
        "\n",
        "# Create the error plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.scatter(x=plot_df_errors['Long'], y=plot_df_errors['Lat'], c=plot_df_errors['Error'], cmap='coolwarm', s=10, alpha=0.7)\n",
        "plt.colorbar(label='Prediction Error (Actual - Predicted)')\n",
        "plt.title('Prediction Error on a Map')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Interpretation of the Error Plot:\n",
        "# - Blue points indicate areas where the model is over-predicting (Predicted > Actual).\n",
        "# - Red points indicate areas where the model is under-predicting (Predicted < Actual).\n",
        "# - White/light points indicate areas where the model is highly accurate.\n",
        "# Look for clusters of red or blue points to identify regions where the model has a systematic bias."
      ],
      "metadata": {
        "id": "7yZrblHBHKze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "df['dist_to_equator'] = np.abs(df['Lat'])\n",
        "\n",
        "# --- New Step: Create a new feature using K-Means clustering ---\n",
        "\n",
        "# Select Lat and Long for clustering\n",
        "geo_data = df[['Lat', 'Long']].values\n",
        "\n",
        "# Use MiniBatchKMeans for faster computation, choosing 20 clusters as a starting point\n",
        "kmeans = MiniBatchKMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df['geo_cluster'] = kmeans.fit_predict(geo_data)\n",
        "\n",
        "# Features and target (now including the new 'geo_cluster' feature)\n",
        "features = ['COUNTRY', 'Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD', 'geo_cluster']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features]\n",
        "y_geo = df[target]\n",
        "\n",
        "categorical_features_geo = ['COUNTRY', 'METHOD', 'geo_cluster']\n",
        "numerical_features_geo = ['Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf']\n",
        "\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_geo),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)\n",
        "    ])\n",
        "\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Re-run the tuned model with the new feature\n",
        "model_geo_tuned = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "model_geo_tuned.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
        "model_geo_tuned.fit(X_train_processed_geo, y_train_geo, epochs=20, batch_size=64, verbose=0)\n",
        "loss_geo_tuned, mae_geo_tuned = model_geo_tuned.evaluate(X_test_processed_geo, y_test_geo, verbose=0)\n",
        "\n",
        "print(f\"Geospatial Regression Model with K-Means Clusters MAE: {mae_geo_tuned:.4f}\")"
      ],
      "metadata": {
        "id": "AniDsICsIIid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for plotting\n",
        "y_pred_geo_tuned = model_geo_tuned.predict(X_test_processed_geo, verbose=0)\n",
        "# Create a DataFrame for plotting\n",
        "plot_df_tuned = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df_tuned['Actual'] = y_test_geo.values\n",
        "plot_df_tuned['Predicted'] = y_pred_geo_tuned\n",
        "\n",
        "# Create a single plot with two subplots for comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Plot actual values\n",
        "scatter_actual = axes[0].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Actual'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[0].set_title('Actual PfPR2-10 Values')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "axes[0].grid(True)\n",
        "fig.colorbar(scatter_actual, ax=axes[0], label='Actual PfPR2-10')\n",
        "\n",
        "# Plot predicted values\n",
        "scatter_predicted = axes[1].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Predicted'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[1].set_title('Predicted PfPR2-10 Values')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "axes[1].grid(True)\n",
        "fig.colorbar(scatter_predicted, ax=axes[1], label='Predicted PfPR2-10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JUHXNlNGnEtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "# --- Load, preprocess, and train the final model ---\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "df['dist_to_equator'] = np.abs(df['Lat'])\n",
        "\n",
        "# Create a new feature using K-Means clustering\n",
        "geo_data = df[['Lat', 'Long']].values\n",
        "kmeans = MiniBatchKMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df['geo_cluster'] = kmeans.fit_predict(geo_data)\n",
        "\n",
        "features = ['COUNTRY', 'Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD', 'geo_cluster']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features]\n",
        "y_geo = df[target]\n",
        "\n",
        "categorical_features_geo = ['COUNTRY', 'METHOD', 'geo_cluster']\n",
        "numerical_features_geo = ['Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf']\n",
        "\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_geo),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)\n",
        "    ])\n",
        "\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "model_geo_tuned = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "model_geo_tuned.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
        "model_geo_tuned.fit(X_train_processed_geo, y_train_geo, epochs=20, batch_size=64, verbose=0)\n",
        "y_pred_geo_tuned = model_geo_tuned.predict(X_test_processed_geo, verbose=0)\n",
        "\n",
        "# --- 1. Visualize the New Model's Errors ---\n",
        "\n",
        "print(\"### Visualizing the New Model's Errors\\n\")\n",
        "\n",
        "plot_df_errors = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df_errors['Error'] = y_test_geo.values - y_pred_geo_tuned.flatten()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.scatter(x=plot_df_errors['Long'], y=plot_df_errors['Lat'], c=plot_df_errors['Error'], cmap='coolwarm', s=10, alpha=0.7)\n",
        "plt.colorbar(label='Prediction Error (Actual - Predicted)')\n",
        "plt.title('Prediction Error on a Map with K-Means Clusters')\n",
        "plt.xlabel('Longitude')\n",
        "plt.ylabel('Latitude')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "sLThL0FbJlHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the data\n",
        "df = pd.read_csv('AfricaDataset.csv.csv')\n",
        "df = df.drop(columns=['Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'ID', 'AFR ADMIN2 Code', 'AFR Admin name', 'AREA_TYPE'])\n",
        "df['dist_to_equator'] = np.abs(df['Lat'])\n",
        "\n",
        "# --- New Step: Create a new feature using K-Means clustering ---\n",
        "\n",
        "# Select Lat and Long for clustering\n",
        "geo_data = df[['Lat', 'Long']].values\n",
        "\n",
        "# Use MiniBatchKMeans for faster computation, choosing 20 clusters as a starting point\n",
        "kmeans = MiniBatchKMeans(n_clusters=5, random_state=42, n_init=10)\n",
        "df['geo_cluster'] = kmeans.fit_predict(geo_data)\n",
        "\n",
        "# Features and target (now including the new 'geo_cluster' feature)\n",
        "features = ['COUNTRY', 'Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf', 'METHOD', 'geo_cluster']\n",
        "target = 'PfPR2-10'\n",
        "X_geo = df[features]\n",
        "y_geo = df[target]\n",
        "\n",
        "categorical_features_geo = ['COUNTRY', 'METHOD', 'geo_cluster']\n",
        "numerical_features_geo = ['Lat', 'Long', 'dist_to_equator', 'MM', 'YY', 'LoAge', 'UpAge', 'Ex', 'Pf']\n",
        "\n",
        "preprocessor_geo = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features_geo),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_geo)\n",
        "    ])\n",
        "\n",
        "X_train_geo, X_test_geo, y_train_geo, y_test_geo = train_test_split(X_geo, y_geo, test_size=0.2, random_state=42)\n",
        "X_train_processed_geo = preprocessor_geo.fit_transform(X_train_geo)\n",
        "X_test_processed_geo = preprocessor_geo.transform(X_test_geo)\n",
        "\n",
        "# Re-run the tuned model with the new feature\n",
        "model_geo_tuned = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=(X_train_processed_geo.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "model_geo_tuned.compile(optimizer='adam', loss='mean_absolute_error', metrics=['mae'])\n",
        "model_geo_tuned.fit(X_train_processed_geo, y_train_geo, epochs=20, batch_size=64, verbose=0)\n",
        "loss_geo_tuned, mae_geo_tuned = model_geo_tuned.evaluate(X_test_processed_geo, y_test_geo, verbose=0)\n",
        "\n",
        "print(f\"Geospatial Regression Model with K-Means Clusters MAE: {mae_geo_tuned:.4f}\")\n",
        "\n",
        "# Generate predictions for plotting\n",
        "y_pred_geo_tuned = model_geo_tuned.predict(X_test_processed_geo, verbose=0)\n",
        "\n",
        "mae = mean_absolute_error(y_test_geo, y_pred_geo_tuned)\n",
        "r2 = r2_score(y_test_geo, y_pred_geo_tuned)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_geo, y_pred_geo_tuned))\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "print(f\"R-squared (R2) Score: {r2:.2f}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "plot_df_tuned = X_test_geo[['Lat', 'Long']].copy()\n",
        "plot_df_tuned['Actual'] = y_test_geo.values\n",
        "plot_df_tuned['Predicted'] = y_pred_geo_tuned\n",
        "\n",
        "# Create a single plot with two subplots for comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "# Plot actual values\n",
        "scatter_actual = axes[0].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Actual'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[0].set_title('Actual PfPR2-10 Values')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "axes[0].grid(True)\n",
        "fig.colorbar(scatter_actual, ax=axes[0], label='Actual PfPR2-10')\n",
        "\n",
        "# Plot predicted values\n",
        "scatter_predicted = axes[1].scatter(x=plot_df_tuned['Long'], y=plot_df_tuned['Lat'], c=plot_df_tuned['Predicted'], cmap='viridis', s=10, alpha=0.7)\n",
        "axes[1].set_title('Predicted PfPR2-10 Values')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "axes[1].grid(True)\n",
        "fig.colorbar(scatter_predicted, ax=axes[1], label='Predicted PfPR2-10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p8_2Y8BdJdKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zNcBpnlhJdNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dKQR4OLaJdPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zfWSiXzJdSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAVpdBR0JdT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUvjf-BLJdW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_S1fP_ZeJdbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XvtzuCBdxD16"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}